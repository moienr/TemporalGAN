{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.cpu_count()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:29.215976Z","iopub.execute_input":"2023-04-09T16:24:29.216678Z","iopub.status.idle":"2023-04-09T16:24:29.260562Z","shell.execute_reply.started":"2023-04-09T16:24:29.216636Z","shell.execute_reply":"2023-04-09T16:24:29.259350Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"gittoken\")\n\n!git clone https://{secret_value}@github.com/moienr/TemporalGAN.git\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:29.263164Z","iopub.execute_input":"2023-04-09T16:24:29.266684Z","iopub.status.idle":"2023-04-09T16:24:34.758224Z","shell.execute_reply.started":"2023-04-09T16:24:29.266634Z","shell.execute_reply":"2023-04-09T16:24:34.756974Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'TemporalGAN'...\nremote: Enumerating objects: 992, done.\u001b[K\nremote: Counting objects: 100% (295/295), done.\u001b[K\nremote: Compressing objects: 100% (135/135), done.\u001b[K\nremote: Total 992 (delta 196), reused 257 (delta 158), pack-reused 697\u001b[K\nReceiving objects: 100% (992/992), 82.96 MiB | 35.39 MiB/s, done.\nResolving deltas: 100% (662/662), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom glob import glob\nfrom skimage import io\nimport os\nfrom torchvision import datasets, transforms","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:34.760532Z","iopub.execute_input":"2023-04-09T16:24:34.760918Z","iopub.status.idle":"2023-04-09T16:24:37.510918Z","shell.execute_reply.started":"2023-04-09T16:24:34.760873Z","shell.execute_reply":"2023-04-09T16:24:37.509867Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import time\nsleep_time = 5\nwhile not os.path.exists(\"/kaggle/working/TemporalGAN\"):\n    print(\"didn't find the path, wating {sleep_time} more seconds...\")\n    time.sleep(sleep_time)\nprint(\"path found...\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.513838Z","iopub.execute_input":"2023-04-09T16:24:37.514511Z","iopub.status.idle":"2023-04-09T16:24:37.522189Z","shell.execute_reply.started":"2023-04-09T16:24:37.514468Z","shell.execute_reply":"2023-04-09T16:24:37.521122Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"path found...\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.523538Z","iopub.execute_input":"2023-04-09T16:24:37.524740Z","iopub.status.idle":"2023-04-09T16:24:37.536419Z","shell.execute_reply.started":"2023-04-09T16:24:37.524699Z","shell.execute_reply":"2023-04-09T16:24:37.535189Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'1.13.0'"},"metadata":{}}]},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.537878Z","iopub.execute_input":"2023-04-09T16:24:37.538457Z","iopub.status.idle":"2023-04-09T16:24:37.607821Z","shell.execute_reply.started":"2023-04-09T16:24:37.538417Z","shell.execute_reply":"2023-04-09T16:24:37.606632Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/TemporalGAN\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.609647Z","iopub.execute_input":"2023-04-09T16:24:37.610071Z","iopub.status.idle":"2023-04-09T16:24:37.615866Z","shell.execute_reply.started":"2023-04-09T16:24:37.610001Z","shell.execute_reply":"2023-04-09T16:24:37.614700Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nfrom dataset.data_loaders import *\nfrom dataset.utils.plot_utils import plot_s1s2_tensors","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.617649Z","iopub.execute_input":"2023-04-09T16:24:37.618272Z","iopub.status.idle":"2023-04-09T16:24:37.630845Z","shell.execute_reply.started":"2023-04-09T16:24:37.618234Z","shell.execute_reply":"2023-04-09T16:24:37.629759Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# transform = transforms.Compose([S2S1Normalize(),myToTensor()])\n\n# print(\"Reading only S1 2021 train data...\")\n# s1s2_dataset = Sen12Dataset(s1_t1_dir=\"E:\\\\s1s2\\\\s1s2_patched_light\\\\s1s2_patched_light\\\\2021\\\\s1_imgs\\\\train\",\n#                             s2_t1_dir=\"E:\\\\s1s2\\\\s1s2_patched_light\\\\s1s2_patched_light\\\\2021\\\\s2_imgs\\\\train\",\n#                             s1_t2_dir=\"E:\\\\s1s2\\\\s1s2_patched_light\\\\s1s2_patched_light\\\\2019\\\\s1_imgs\\\\train\",\n#                             s2_t2_dir=\"E:\\\\s1s2\\\\s1s2_patched_light\\\\s1s2_patched_light\\\\2019\\\\s2_imgs\\\\train\",\n#                             transform=transform,\n#                             two_way=False)\n# print(\"len(s1s2_dataset): \",len(s1s2_dataset))\n# print(\"s1s2_dataset[0][0]shape: \",s1s2_dataset[0][1].shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.632364Z","iopub.execute_input":"2023-04-09T16:24:37.632752Z","iopub.status.idle":"2023-04-09T16:24:37.637876Z","shell.execute_reply.started":"2023-04-09T16:24:37.632704Z","shell.execute_reply":"2023-04-09T16:24:37.636611Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# plot_s1s2_tensors(s1s2_dataset[1], [\"s2t2\", \"s1t2\", \"s2t1\", \"s1t1\", \"change map\", \"reversed change map\"], 3,2)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.642477Z","iopub.execute_input":"2023-04-09T16:24:37.642903Z","iopub.status.idle":"2023-04-09T16:24:37.647464Z","shell.execute_reply.started":"2023-04-09T16:24:37.642872Z","shell.execute_reply":"2023-04-09T16:24:37.646436Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"S2_INCHANNELS = 6\nS1_INCHANNELS = 1\nLEARNING_RATE = 2e-4\nBATCH_SIZE = 1\nNUM_WORKERS = 2\nIMAGE_SIZE = 256\nWEIGHTED_LOSS = True\nINPUT_CHANGE_MAP = False\nL1_LAMBDA = 100\nLAMBDA_GP = 10\nNUM_EPOCHS = 5\nLOAD_MODEL = False\nSAVE_MODEL = False\nSAVE_EVERY_EPOCH = 1\nCHECKPOINT_DISC = \"disc.pth.tar\"\nCHECKPOINT_GEN = \"gen.pth.tar\"","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.649209Z","iopub.execute_input":"2023-04-09T16:24:37.649988Z","iopub.status.idle":"2023-04-09T16:24:37.656844Z","shell.execute_reply.started":"2023-04-09T16:24:37.649950Z","shell.execute_reply":"2023-04-09T16:24:37.655823Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom torchvision.utils import save_image\n\ndef save_some_examples(gen, val_loader, epoch, folder):\n    x, y = next(iter(val_loader))\n    x, y = x.to(DEVICE), y.to(DEVICE)\n    gen.eval()\n    with torch.no_grad():\n        y_fake = gen(x)\n        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n        if epoch == 1:\n            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n    gen.train()\n\n\ndef save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)\n\n\ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.658448Z","iopub.execute_input":"2023-04-09T16:24:37.659567Z","iopub.status.idle":"2023-04-09T16:24:37.670054Z","shell.execute_reply.started":"2023-04-09T16:24:37.659525Z","shell.execute_reply":"2023-04-09T16:24:37.669177Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n\ntorch.backends.cudnn.benchmark = True\n\n\ndef train_fn(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler, weighted_loss = WEIGHTED_LOSS, cm_input = INPUT_CHANGE_MAP):\n    loop = tqdm(loader, leave=True)\n\n    for idx, (s2t1,s1t1,s2t2,s1t2,cm,rcm) in enumerate(loop):\n        s2t1,s1t1,s2t2,s1t2,cm,rcm = s2t1.to(DEVICE),s1t1.to(DEVICE),s2t2.to(DEVICE),s1t2.to(DEVICE),cm.to(DEVICE),rcm.to(DEVICE)\n        if cm_input:\n            s2t2 = torch.cat((s2t2, cm), dim=1)\n            s1t1 = torch.cat((s1t1, rcm), dim=1)\n        # Train Discriminator\n        with torch.cuda.amp.autocast():\n            s1t2_fake = gen(s2t2, s1t1)\n            D_real = disc(s2t2, s1t1, s1t2)\n            D_real_loss = bce(D_real, torch.ones_like(D_real))\n            D_fake = disc(s2t2, s1t1, s1t2_fake.detach())\n            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n            D_loss = (D_real_loss + D_fake_loss) / 2\n\n        disc.zero_grad()\n        d_scaler.scale(D_loss).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n\n        # Train generator\n        with torch.cuda.amp.autocast():\n            D_fake = disc(s2t2, s1t1, s1t2_fake)\n            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n            if weighted_loss:\n                L1 = l1_loss(s1t2_fake, s1t2, cm, rcm) * L1_LAMBDA\n            else:\n                L1 = l1_loss(s1t2_fake, s1t2) * L1_LAMBDA\n            G_loss = G_fake_loss + L1\n\n        opt_gen.zero_grad()\n        g_scaler.scale(G_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n\n        if idx % 10 == 0:\n            loop.set_postfix(\n                D_real=torch.sigmoid(D_real).mean().item(),\n                D_fake=torch.sigmoid(D_fake).mean().item(),\n                G_loss = G_loss.item(),\n                L1 = L1.item(),\n            )\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.671738Z","iopub.execute_input":"2023-04-09T16:24:37.672664Z","iopub.status.idle":"2023-04-09T16:24:37.686193Z","shell.execute_reply.started":"2023-04-09T16:24:37.672624Z","shell.execute_reply":"2023-04-09T16:24:37.685445Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from temporalgan.temporal_gan_v3_gen import Generator as GeneratorV3\nfrom temporalgan.temporal_gan_v2_gen import Generator as GeneratorV2\nfrom temporalgan.temporal_gan_v1_gen import Generator as GeneratorV1\nfrom temporalgan.temporal_gan_v2_disc import Discriminator as DiscriminatorV2\nfrom temporalgan.temporal_gan_v1_disc import Discriminator as DiscriminatorV1\nfrom temporalgan.lossfunciton.loss_function import WeightedL1Loss","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.687847Z","iopub.execute_input":"2023-04-09T16:24:37.688629Z","iopub.status.idle":"2023-04-09T16:24:37.710856Z","shell.execute_reply.started":"2023-04-09T16:24:37.688586Z","shell.execute_reply":"2023-04-09T16:24:37.710162Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def main():\n    disc = DiscriminatorV1(s2_in_channels=S2_INCHANNELS, s1_in_channels=S1_INCHANNELS).to(DEVICE)\n    gen = GeneratorV3(s2_in_channels=S2_INCHANNELS, s1_in_channels= S1_INCHANNELS, features=64,pam_downsample=2).to(DEVICE)\n    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n    BCE = nn.BCEWithLogitsLoss()\n    if WEIGHTED_LOSS:\n        L1_LOSS = WeightedL1Loss(change_weight=5)\n    else:\n        L1_LOSS = nn.L1Loss()\n\n    if LOAD_MODEL:\n        load_checkpoint(\n            CHECKPOINT_GEN, gen, opt_gen, LEARNING_RATE,\n        )\n        load_checkpoint(\n            CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n        )\n\n    transform = transforms.Compose([S2S1Normalize(),myToTensor()])\n\n\n    train_dataset = Sen12Dataset(s1_t1_dir=\"/kaggle/input/s1s2-2021-v2/2021/s1_imgs/train\",\n                                s2_t1_dir=\"/kaggle/input/s1s2-2021-v2/2021/s2_imgs/train\",\n                                s1_t2_dir=\"/kaggle/input/s1s2-2019-v2/2019/s1_imgs/train\",\n                                s2_t2_dir=\"/kaggle/input/s1s2-2019-v2/2019/s2_imgs/train\",\n                                transform=transform,\n                                two_way=False)\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n    )\n    g_scaler = torch.cuda.amp.GradScaler()\n    d_scaler = torch.cuda.amp.GradScaler()\n#     val_dataset = MapDataset(root_dir=VAL_DIR)\n#     val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n\n    for epoch in range(1, NUM_EPOCHS+1):\n        print(f\"Epoch: {epoch}\")\n        train_fn(\n            disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,\n        )\n\n        if SAVE_MODEL and epoch % SAVE_EVERY_EPOCH == 0:\n            save_checkpoint(epoch,gen, opt_gen, filename=CHECKPOINT_GEN)\n            save_checkpoint(epoch,disc, opt_disc, filename=CHECKPOINT_DISC)\n\n#         save_some_examples(gen, val_loader, epoch, folder=\"evaluation\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.712331Z","iopub.execute_input":"2023-04-09T16:24:37.713053Z","iopub.status.idle":"2023-04-09T16:24:37.724202Z","shell.execute_reply.started":"2023-04-09T16:24:37.713013Z","shell.execute_reply":"2023-04-09T16:24:37.723202Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T16:24:37.725342Z","iopub.execute_input":"2023-04-09T16:24:37.725636Z","iopub.status.idle":"2023-04-09T16:25:12.382711Z","shell.execute_reply.started":"2023-04-09T16:24:37.725610Z","shell.execute_reply":"2023-04-09T16:25:12.380800Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 58/1326 [00:28<10:13,  2.07it/s, D_fake=0.484, D_real=0.514, G_loss=82.9, L1=82.1]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/508855414.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         train_fn(\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdisc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1_LOSS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_scaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/2829815477.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler, weighted_loss, cm_input)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Train Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0ms1t2_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2t2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1t1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2t2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1t1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1t2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mD_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/TemporalGAN/temporalgan/temporal_gan_v3_gen.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s2, s1)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# No Spatial Attention Module for the last two layers, when downsampling, but we send their CBAM to be concatenated with the upsampled layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0md5_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms1_down4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md4_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0md6_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms1_down5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md5_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0md7_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms1_down6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md6_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Now we fuse the two streams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/TemporalGAN/temporalgan/submodules/gen_cnn_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_dropout\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_no_batch_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_instance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36m_apply_instance_norm\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     34\u001b[0m         return F.instance_norm(\n\u001b[1;32m     35\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minstance_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[1;32m   2494\u001b[0m         \u001b[0m_verify_spatial_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     return torch.instance_norm(\n\u001b[0;32m-> 2496\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m     )\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}